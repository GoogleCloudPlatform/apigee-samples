{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QC8yC7SoSMn"
   },
   "source": [
    "# **Apigee GenAI Workshop**\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td style=\"text-align: center\">\n",
    "      <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/apigee-samples/blob/genai-workshop/genai-workshop.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\\\"><br> Open in Colab\n",
    "      </a>\n",
    "    </td>\n",
    "    <td style=\"text-align: center\">\n",
    "      <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fapigee-samples%2Fgenai-workshop%2Fgenai-workshop.ipynb\">\n",
    "        <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "      </a>\n",
    "    </td>    \n",
    "    <td style=\"text-align: center\">\n",
    "      <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/apigee-samples/genai-workshop/genai-workshop.ipynb\">\n",
    "        <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "      </a>\n",
    "    </td>\n",
    "    <td style=\"text-align: center\">\n",
    "      <a href=\"https://github.com/GoogleCloudPlatform/apigee-samples/blob/genai-workshop/genai-workshop.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "      </a>\n",
    "    </td>\n",
    "</table>\n",
    "<br />\n",
    "<br />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to Google's Apigee GenAI Workshop! \n",
    "\n",
    "This hands-on workshop will equip you with the knowledge and skills to leverage the power of Generative AI within your API ecosystem. Through practical exercises and real-world examples, you'll learn how to seamlessly integrate Large Language Models (LLMs) with Apigee, Google's leading API management platform. Get ready to unlock new possibilities and explore the exciting world of GenAI and APIs!\n",
    "\n",
    "You should already have a lab instance up and running with all the necessary artifacts (Apigee, Vertex AI, Vertex DB, etc) provisioned for you to use. \n",
    "\n",
    "First, lets install the necessary dependencies to run the labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AuXsoJDZPMs"
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install langchain_google_vertexai\n",
    "!pip install langchain-openai\n",
    "!pip install google-cloud-aiplatform\n",
    "!pip install google-cloud-tasks\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4eVYn8frc5i"
   },
   "source": [
    "## Initialize notebook variables\n",
    "\n",
    "You can fetch all the variables from your lab instance\n",
    "\n",
    "* **PROJECT_ID**: The default GCP project to use when making Vertex API calls.\n",
    "* **REGION**: The default location to use when making API calls.\n",
    "* **APIGEE_HOSTNAME**:  The hostname of your Apigee instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kj-10KmnZSVe"
   },
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "LOCATION = \"\"  # @param {type:\"string\"}\n",
    "APIGEE_HOSTNAME = \"\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: LLM-Logging with Apigee\n",
    "\n",
    "Logging both prompts and candidate responses from large language models (LLMs) allows for detailed analysis and improvement of the model's performance over time. By examining past interactions, AI practitioners can identify patterns leading to refinements in the training data or model architecture. Furthermore, by examining the prompts security teams can detect malicious intent, such as attempts to extract sensitive information or generate harmful content.\n",
    "\n",
    "Additionally, logging the generated candidates provides insights into the LLM's behavior and helps identify any biases or vulnerabilities in the model itself. This information can then be used to improve security measures, fine-tune the model, and mitigate potential risks associated with LLM usage.\n",
    "\n",
    "![image](https://github.com/GoogleCloudPlatform/apigee-samples/blob/main/llm-logging/images/llm-logging.png?raw=1)\n",
    "\n",
    "\n",
    "### Benefits of Logging with Apigee and Google Cloud Logging\n",
    "\n",
    "* **Seamless logging**: Effortlessly capture prompts, candidate responses, and metadata without complex coding.\n",
    "* **Scalable and secure**: Leverage Google Cloud's infrastructure for reliable and secure log management.\n",
    "\n",
    "### How does it work?\n",
    "\n",
    "1. Prompt request is receved by an Apigee Proxy.\n",
    "2. Apigee extracts prompt and candidate responses.\n",
    "3. Apigee logs prompt and candidate responses to Cloud Logging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S478piq-SGLc"
   },
   "source": [
    "### Test Sample\n",
    "\n",
    "Apigee allows you to seamlessly send logs to Cloud Logging using native integration with the [Message Logging](https://cloud.google.com/apigee/docs/api-platform/reference/policies/message-logging-policy#cloudloggingelement) policy. This sample also includes a message chunking solution that allows logging very long messages (ex. 1M tokens supported by Gemini) and connecting them together using a unique message identifier.\n",
    "\n",
    "With the following cell you'll be able to invoke an LLM and both prompt and candidate resposne will be logged in Cloud Logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87i610BzZns_"
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAI\n",
    "API_ENDPOINT = \"https://\"+APIGEE_HOSTNAME+\"/v1/samples/llm-logging\"\n",
    "# Initialize Langchain\n",
    "model = VertexAI(\n",
    "      project=PROJECT_ID,\n",
    "      location=LOCATION,\n",
    "      api_endpoint=API_ENDPOINT,\n",
    "      api_transport=\"rest\",\n",
    "      streaming=True,\n",
    "      model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "prompts = [\"Provide an explanation about the benefits of using sunscreen. Make sure to make it as long as a novel.\"]\n",
    "\n",
    "for prompt in prompts:\n",
    "  print(model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjW8UBEnZg9U"
   },
   "source": [
    "### Explore and Analyze Logs with Cloud Logging\n",
    "\n",
    "1. Navigate to the Cloud Logging Explorer by [**clicking here**](https://console.cloud.google.com/logs/query?_ga=2.194228271.307340908.1727018794-898542846.1726863667).\n",
    "\n",
    "2. Set the query filter. Make sure to replace the `PROJECT_ID` with the Apigee project ID:\n",
    "\n",
    "  ```\n",
    "  logName=\"projects/PROJECT_ID/logs/apigee\"\n",
    "  ```\n",
    "3. Run the query and explore the logs. See example below:\n",
    "\n",
    "  ![image](https://github.com/GoogleCloudPlatform/apigee-samples/blob/main/llm-logging/images/logs-explorer.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
