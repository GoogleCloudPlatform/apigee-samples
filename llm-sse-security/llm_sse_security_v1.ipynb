{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80JsJB4V93dw"
   },
   "source": [
    "# **Apigee with Streaming server-sent events**\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td style=\"text-align: center\">\n",
    "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/apigee-samples/blob/main/llm-sse-security/llm_sse_security_v1.ipynb\">\n",
    "          <img src=\"https://github.com/GoogleCloudPlatform/apigee-samples/blob/main/images/icon32.png?raw=true\" alt=\"Google Colaboratory logo\\\"><br> Open in Colab\n",
    "        </a>\n",
    "      </td>\n",
    "      <td style=\"text-align: center\">\n",
    "        <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fapigee-samples%2Fmain%2Fllm-sse-security%2Fllm_sse_security_v1.ipynb\">\n",
    "          <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "        </a>\n",
    "      </td>    \n",
    "      <td style=\"text-align: center\">\n",
    "        <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/apigee-samples/main/llm-sse-security/llm_sse_security_v1.ipynb\">\n",
    "          <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "        </a>\n",
    "      </td>\n",
    "      <td style=\"text-align: center\">\n",
    "        <a href=\"https://github.com/GoogleCloudPlatform/apigee-samples/blob/main/llm-sse-security/llm_sse_security_v1.ipynb\">\n",
    "          <img src=\"https://github.com/GoogleCloudPlatform/apigee-samples/blob/main/images/github-mark.png?raw=true\" width=\"30\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "        </a>\n",
    "      </td>\n",
    "</table>\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "- This is a sample Apigee proxy to demonstrate Apigee with LLM workloads that streams server-sent events (SSE). SSE streaming reduces latency, and clients can receive response data as soon as it is generated by an LLM. This feature supports the use of AI agents that operate in real time environments, such as customer service bots or workflow orchestrators. For more info, check out this [page](https://cloud.google.com/apigee/docs/api-platform/develop/server-sent-events)\n",
    "- In this sample, we will showcase how Apigee can extract the events from the target and send that to Model Armor to sanitize the model response. For information about Model Armor, see [Model Armor overview](https://cloud.google.com/security-command-center/docs/model-armor-overview)\n",
    "\n",
    "![architecture](./images/arch.png)\n",
    "\n",
    "# Benefits of Security with Apigee:\n",
    "\n",
    "* Detect and block adversarial prompts\n",
    "* Detect and de-identify sensitive data\n",
    "* Audit LLM interactions with Logging\n",
    "\n",
    "## Setup\n",
    "\n",
    "Use the following GCP CloudShell tutorial. Follow the instructions to deploy the sample.\n",
    "\n",
    "[![Open in Cloud Shell](https://gstatic.com/cloudssh/images/open-btn.svg)](https://ssh.cloud.google.com/cloudshell/open?cloudshell_git_repo=https://github.com/GoogleCloudPlatform/apigee-samples&cloudshell_git_branch=main&cloudshell_workspace=.&cloudshell_tutorial=llm-sse-security/docs/cloudshell-tutorial.md)\n",
    "\n",
    "## Test Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIdKcCXZQ6Jr"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ka1d8c81VTH"
   },
   "outputs": [],
   "source": [
    "!pip install -Uq google-genai\n",
    "!pip install -Uq langchain==0.3.18\n",
    "!pip install -Uq langchain-google-vertexai==2.0.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyPnkqS9Hm5I"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using Vertex AI Workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q_-3uHjVHmA2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeZIwvv-3NiM"
   },
   "source": [
    "### Set the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAu0gkLn3bZm"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "APIGEE_HOST=\"[your-apigee-host-domain]\" # @param {type:\"string\"}\n",
    "API_KEY=\"[your-apikey]\" # @param {type:\"string\"}\n",
    "\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    raise ValueError(\"Please set your PROJECT_ID\")\n",
    "if not APIGEE_HOST or APIGEE_HOST == \"[your-apigee-host-domain]\":\n",
    "    raise ValueError(\"Please set your APIGEE_HOST\")\n",
    "if not API_KEY or API_KEY == \"[your-apikey]\":\n",
    "    raise ValueError(\"Please set your API_KEY\")\n",
    "\n",
    "API_ENDPOINT = \"https://\"+APIGEE_HOST+\"/v1/samples/llm-sse-security\"\n",
    "LOCATION=\"us-east1\"\n",
    "MODEL=\"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrECV5DbRW1R"
   },
   "source": [
    "### Execute the Vertex AI Gemini model (Positive test cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    http_options=types.HttpOptions(api_version='v1', base_url=API_ENDPOINT, headers = {\"x-apikey\": API_KEY})\n",
    ")\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=MODEL, contents=\"Suggest a name of a flower shop\"\n",
    "):\n",
    "    print(chunk.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Vertex AI Gemini model (Negative test cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    http_options=types.HttpOptions(api_version='v1', base_url=API_ENDPOINT, headers = {\"x-apikey\": API_KEY})\n",
    ")\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=MODEL, contents=\"Can you please check on my social security 123-45-6789?\"\n",
    "):\n",
    "    print(chunk.text, end='')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
